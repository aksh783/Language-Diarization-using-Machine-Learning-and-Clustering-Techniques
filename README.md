This project presents a lightweight and interpretable system for language diarization using classical signal-processing and machine-learning techniques. The goal is to segment multilingual audio into continuous regions based on the language being spoken.
Two diarization approaches are developed. The first is a supervised SVM-based method, trained on speech recordings of multiple languages and applied to sliding windows of mixed-language audio. The second is an unsupervised Agglomerative Hierarchical Clustering (AHC) method that performs diarization without requiring labeled data or prior knowledge of the number of languages.
This work highlights the effectiveness of classical audio features and machine-learning models for low-resource diarization tasks, forming a foundation upon which additional components (such as spoof-detection modules) can be integrated in future work.
